{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework week08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T15:53:00.997444Z",
     "start_time": "2024-03-26T15:52:59.967733Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 [Speculative Sampling][4 points]\n",
    "\n",
    "Algorithm for accelerating transformer decoding by enabling the generation of multiple tokens from each transformer call. Our algorithm relies on the observation that the latency of parallel scoring of short continuations, generated by a faster but less powerful draft model, is comparable to that of sampling a single token from the larger target model.\n",
    "\n",
    "\n",
    "Carefully read https://arxiv.org/abs/2302.01318"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregressive Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"654\" alt=\"image\" src=\"https://github.com/markovka17/dla/assets/20357655/db624e40-d4f0-4e36-88e7-b58a6c646738\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take `EleutherAI/gpt-neo-1.3B` LM as a draft model from https://huggingface.co and generate a couple dozen tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T15:57:56.225866Z",
     "start_time": "2024-03-26T15:57:20.935403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      " The quick brown fox jumps over the lazy dog... it always has, even when it tried too.\n",
      "\n",
      "—The Swing Department by Stephen Crane\n",
      "\n",
      "The Ethics of Investor Relations in Crowdfunding\n",
      "\n",
      "\n",
      "\n",
      "People can back the crunch offbx with all that they've got—not even perverted religion yet. They should have the screen magnifying glasses of Hitachi Capital in the bite marks on the neck of the black cash cow who put their Beautiful Gestation of facebook's Facebook\n"
     ]
    }
   ],
   "source": [
    "# Ensure that your device is set correctly (GPU or CPU)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "model = AutoModelForCausalLM.from_pretrained('EleutherAI/gpt-neo-1.3B', torch_dtype=torch.float32).to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Prepare a text prompt\n",
    "text_prompt = [\"The quick brown fox jumps\"]\n",
    "inputs = tokenizer(text_prompt, return_tensors='pt').to(device)  # Tokenize the text prompt and convert to tensor\n",
    "\n",
    "# Perform text generation (inference)\n",
    "# Note: manual handling means we will manage the generated text and stop criteria without using generate() method\n",
    "max_length = 100  # Maximum length of the generated text\n",
    "temperature = 1.0  # Sampling temperature, higher values mean more randomness\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation for inference\n",
    "    output_sequence = inputs['input_ids']\n",
    "    for _ in range(max_length - inputs['input_ids'].size(1)):\n",
    "        # Predict the next token\n",
    "        logits = model(output_sequence).logits[:, -1, :]\n",
    "        \n",
    "        # Apply temperature\n",
    "        logits = logits / temperature\n",
    "        \n",
    "        # Sample the next token from the probability distribution\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        next_token = torch.multinomial(probabilities, num_samples=1)\n",
    "        \n",
    "        # Append the predicted token to the output sequence\n",
    "        output_sequence = torch.cat([output_sequence, next_token], dim=1)\n",
    "\n",
    "        # Check if the end-of-sequence token (EOS) was generated\n",
    "        if next_token.item() == tokenizer.eos_token_id:\n",
    "            break\n",
    "\n",
    "# Decode and print the generated text\n",
    "generated_text = tokenizer.decode(output_sequence.squeeze(), skip_special_tokens=True)\n",
    "print(\"Generated text:\\n\", generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1\n",
    "\n",
    "Ans let's use `EleutherAI/gpt-j-6B` as target model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T15:57:09.693796Z",
     "start_time": "2024-03-26T15:57:09.691890Z"
    }
   },
   "outputs": [],
   "source": [
    "# large_model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\", torch_dtype=torch.float32).to(device)\n",
    "# large_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In speculative sampling, we have two models:\n",
    "\n",
    "    A smaller, faster draft model (e.g. EleutherAI/gpt-neo-1.3B model)\n",
    "    A larger, slower target model (e.g. EleutherAI/gpt-j-6B model)\n",
    "\n",
    "The idea is that the draft model speculates what the output is steps into the future, while the target model determines how many of those tokens we should accept. Here's an outline of the algorithm:\n",
    "\n",
    "The draft model decodes tokens in the regular autoregressive fashion.\n",
    "We get the probability outputs of the target and draft model on the new predicted sequence.\n",
    "We compare the target and draft model probabilities to determine how many of the tokens we want to keep based on some rejection criteria. If a token is rejected, we resample it using a combination of the two distributions and don't accept any more tokens.\n",
    "If all tokens are accepted, we can sample an additional final token from the target model probability output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"635\" alt=\"image\" src=\"https://github.com/markovka17/dla/assets/20357655/3954894d-8735-4f92-a835-d04eac74f190\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def sample_new_token(model, tokens, temp: float = 1.0):\n",
    "    '''Sample new token given model and prompt. '''\n",
    "    logits = model(tokens).logits[:, -1, :] / temp \n",
    "    probas = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    new_token = torch.multinomial(probas, num_samples=1)\n",
    "    return new_token, logits\n",
    "\n",
    "\n",
    "def build_parallel_batch(old_tokens, new_tokens):\n",
    "    '''Build batch by concatenating old and new tokens. '''\n",
    "    k = new_tokens.size(1)\n",
    "    tokens = torch.cat([old_tokens.tile(k, 1), torch.tril(new_tokens.tile(k, 1))], dim=1)\n",
    "    return tokens, (tokens != 0) * 1.0\n",
    "\n",
    "\n",
    "def get_target_logits(target_model, old_tokens, new_tokens, temp: float = 1.0):\n",
    "    '''Obtain target logits in parallel from target model. '''\n",
    "    tokens_batch, attn_masks = build_parallel_batch(old_tokens, new_tokens)\n",
    "    idxs = torch.arange(old_tokens.size(1), old_tokens.size(1) + new_tokens.size(1)) - 1\n",
    "    logits = target_model(\n",
    "        input_ids=tokens_batch, attention_mask=attn_masks\n",
    "    ).logits[torch.arange(tokens_batch.size(0)), idxs, :] / temp\n",
    "    return logits   \n",
    "\n",
    "\n",
    "def simulate_with_draft(draft_model, x_draft, K):\n",
    "    '''Simulate K draft tokens from the draft model. '''\n",
    "    new_tokens, draft_logits = [], []\n",
    "    for _ in range(K):\n",
    "        new_token, new_token_proba = sample_new_token(draft_model, x_draft)\n",
    "        x_draft = torch.cat([x_draft, new_token], dim=1)\n",
    "        \n",
    "        new_tokens.append(new_token)\n",
    "        draft_logits.append(new_token_proba)\n",
    "\n",
    "    return torch.cat(new_tokens, dim=1), torch.cat(draft_logits, dim=0)\n",
    "\n",
    "\n",
    "def run_rejection_sampling(target_logits, draft_logits, draft_tokens, x, K, EOS=tokenizer.eos_token_id):\n",
    "    '''Run rejection sampling given target and draft logits. '''\n",
    "    n_accepted = 0\n",
    "    all_accepted = True\n",
    "    is_eos = False\n",
    "    \n",
    "    for idx in range(K):        \n",
    "        next_token = draft_tokens[:, idx]\n",
    "\n",
    "        q = torch.nn.functional.softmax(target_logits[idx], dim=-1)[next_token]\n",
    "        p = torch.nn.functional.softmax(draft_logits[idx], dim=-1)[next_token]\n",
    "        \n",
    "        if torch.rand(1) < torch.minimum(torch.ones(1), q / p):\n",
    "            n_accepted += 1\n",
    "        else:\n",
    "            all_accepted = False\n",
    "            \n",
    "            fall_back_logits = torch.nn.functional.relu(target_logits[idx] - draft_logits[idx])\n",
    "            fall_back_proba = torch.nn.functional.softmax(fall_back_logits, dim=-1)\n",
    "            next_token = torch.multinomial(fall_back_proba, num_samples=1)\n",
    "\n",
    "        if next_token.item() == EOS:\n",
    "            is_eos = True\n",
    "            break\n",
    "    \n",
    "        x = torch.cat([x, next_token.reshape(1, -1)], dim=1)\n",
    "        if not all_accepted:\n",
    "            break\n",
    "\n",
    "    acc_ration = 1.0 if is_eos and all_accepted else n_accepted / K\n",
    "    return x, all_accepted, is_eos, acc_ration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The backbone of the speculative sample. Feel free to modify it\n",
    "@torch.no_grad()\n",
    "def speculative_sampling(x, draft_model, target_model, N, K):\n",
    "    # NOTE: paper indexes arrays starting from 1, python indexes from 0, so\n",
    "    # we have to add an extra -1 term when indexing using n, T, or t\n",
    "    n = len(x)\n",
    "    acceptance_ratios = []\n",
    "\n",
    "    for _ in range(N):\n",
    "        # Step 1: auto-regressive decode K tokens from draft model and get final p\n",
    "        x_draft = x\n",
    "        draft_tokens, draft_logits = simulate_with_draft(draft_model, x_draft, K)        \n",
    "        \n",
    "        # Step 2: target model forward passes on x_draft\n",
    "        target_logits = get_target_logits(target_model, x, draft_tokens)\n",
    "        assert draft_logits.size(0) == target_logits.size(0) == K, \"Eto posos\"\n",
    "        \n",
    "        # Step 3: append draft tokens based on rejection criterion and resample a token on rejection\n",
    "        x, all_accepted, is_eos, acc_ratio = run_rejection_sampling(\n",
    "            target_logits, draft_logits, draft_tokens, x, K\n",
    "        )\n",
    "        acceptance_ratios.append(acc_ratio)\n",
    "        if is_eos or x.size(1) >= N:\n",
    "            break\n",
    "\n",
    "        # Step 4: if all draft tokens were accepted, sample a final token\n",
    "        if all_accepted:\n",
    "            next_token, _ = sample_new_token(target_model, x)\n",
    "            \n",
    "            if next_token.item() == tokenizer.eos_token_id:\n",
    "                break\n",
    "            \n",
    "            x = torch.cat([x, next_token], dim=1)\n",
    "\n",
    "        if x.size(1) >= N:\n",
    "            break\n",
    "\n",
    "    return x, acceptance_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy example for quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_model = model\n",
    "target_model = model\n",
    "x = inputs['input_ids']\n",
    "\n",
    "N = 16\n",
    "K = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, acc_ratio = speculative_sampling(x, draft_model, target_model, N, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2,\n",
    "\n",
    "Compare the speed of SpS with ArS. The expected speed increase is 30-50%. \n",
    "The speedup is equal to `(time spent by ArS)` / `(time spend by SpS)`\n",
    "\n",
    "Use same start prompt `The quick brown fox jumps`, `K=16` and `K=32` (compare two scenarios) and `max_length=512`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N , K = 512, 16\n",
    "start = time()\n",
    "*_ = speculative_sampling(x, draft_model, target_model, N, K)\n",
    "print(f\"Time taken: {time() - start:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N , K = 512, 32\n",
    "start = time()\n",
    "*_ = speculative_sampling(x, draft_model, target_model, N, K)\n",
    "print(f\"Time taken: {time() - start:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3\n",
    "\n",
    "Visualise acceptence rate for `K=[16, 32, 64, 128]`, same start prompt and `max_length max_length=1024`, where graft model is `EleutherAI/gpt-neo-1.3B` and target model if `EleutherAI/gpt-j-6B`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "rates = []\n",
    "\n",
    "# for K in [16, 32, 64, 128]:\n",
    "for K in [2, 4, 8]:\n",
    "    x = inputs['input_ids']\n",
    "    _, acc_rate = speculative_sampling(x, draft_model, target_model, N, K)\n",
    "    rates.append(acc_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "3\n",
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "for rate, K in zip(rates, [2, 4, 8]):\n",
    "    print(len(rate))\n",
    "    plt.plot(rate, label=f\"{K=}\")\n",
    "\n",
    "plt.title(\"Acceptance ration depending on the number of drafts (K)\")\n",
    "plt.xlabel(\"Number of steps\")\n",
    "plt.ylabel(\"Acceptance ratio\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Task 2 [GroupNorm in Triton][6 points]\n",
    "\n",
    "\n",
    "You need to implement a 2D GroupNorm (https://pytorch.org/docs/stable/generated/torch.nn.GroupNorm.html) and compare it to the PyTorch implementation.\n",
    "Note that GroupNorm is very similar to LayerNorm, so you can see the LayerNorm implementation here https://triton-lang.org/main/getting-started/tutorials/05-layer-norm.html#."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import triton\n",
    "# import triton.language as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def _group_norm_fwd_fused(\n",
    "    X,  # pointer to the input\n",
    "    Y,  # pointer to the output\n",
    "    W,  # pointer to the weights\n",
    "    B,  # pointer to the biases\n",
    "    Mean,  # pointer to the mean\n",
    "    Rstd,  # pointer to the 1/std\n",
    "    stride,  # how much to increase the pointer when moving by 1 row\n",
    "    N,  # number of columns in X\n",
    "    num_groups,  # number of groups\n",
    "    eps,  # epsilon to avoid division by zero\n",
    "    BLOCK_SIZE: tl.constexpr,  # Same parameters as in matmul from seminar\n",
    "):\n",
    "    \"\"\"\n",
    "    Similar to forward of nn.GroupNorm.forward\n",
    "    \"\"\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def _group_norm_bwd_dx_fused(\n",
    "    DX,  # pointer to the input gradient\n",
    "    DY,  # pointer to the output gradient\n",
    "    DW,  # pointer to the partial sum of weights gradient\n",
    "    DB,  # pointer to the partial sum of biases gradient\n",
    "    X,  # pointer to the input\n",
    "    W,  # pointer to the weights\n",
    "    B,  # pointer to the biases\n",
    "    Mean,  # pointer to the mean\n",
    "    Rstd,  # pointer to the 1/std\n",
    "    stride,  # how much to increase the pointer when moving by 1 row\n",
    "    N,  # number of columns in X\n",
    "    eps,  # epsilon to avoid division by zero\n",
    "    GROUP_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr  # Same parameters as in matmul from seminar\n",
    "):\n",
    "    \"\"\"\n",
    "    Backward of GroupNorm respect to input\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def _group_norm_bwd_dwdb(\n",
    "    DW,  # pointer to the partial sum of weights gradient\n",
    "    DB,  # pointer to the partial sum of biases gradient\n",
    "    FINAL_DW,  # pointer to the weights gradient\n",
    "    FINAL_DB,  # pointer to the biases gradient\n",
    "    M,  # GROUP_SIZE_M\n",
    "    N,  # number of columns\n",
    "    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr  # Same parameters as in matmul from seminar\n",
    "):\n",
    "    \"\"\"\n",
    "    Backward of GroupNorm respect to weights and biases (affine transform parameters)\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNorm(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, num_groups, weight, bias, eps):\n",
    "        assert x.size(2) % num_groups == 0, \"channel dim is not divisible by num_groups\"\n",
    "\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.reshape(B, num_groups, C // num_groups, H, W)\n",
    "        x = x.reshape(B, num_groups, C // num_groups * H, W)\n",
    "        x = x.countiguos()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx):\n",
    "        pass\n",
    "\n",
    "group_norm = GroupNorm.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 32, 64, 64)\n",
    "num_groups = 8\n",
    "eps=1e-9\n",
    "weight = torch.rand(32, requires_grad=True)\n",
    "bias = torch.rand(32, requires_grad=True)\n",
    "\n",
    "true_out = torch.nn.functional.group_norm(x, num_groups, weight, bias, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_group_norm(x, num_groups, weight, bias, eps):\n",
    "    B, C, H, W = x.shape\n",
    "    x = x.reshape(B, num_groups, C // num_groups, H, W)\n",
    "    x = x.reshape(B * num_groups, C // num_groups * H * W)\n",
    "    # # x = x.contiguos()\n",
    "    # mean = x.mean(dim=-1, keepdims=True)\n",
    "    # var = x.var(dim=-1, keepdims=True)\n",
    "\n",
    "    # y = (x - mean) / (var + eps).sqrt()\n",
    "    y = torch.nn.functional.layer_norm(x, [C // num_groups * H * W], weight, bias, eps)\n",
    "    \n",
    "    y = y.reshape(B,  num_groups, C // num_groups,  H,  W)\n",
    "    y = y.reshape(B,  C,  H,  W)\n",
    "    return y * weight.reshape(1, -1, 1, 1) + bias.reshape(1, -1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected weight to be of same shape as normalized_shape, but got weight of shape [32] and normalized_shape = [16384]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39mallclose(\u001b[43mfalse_group_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m, true_out, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[32], line 10\u001b[0m, in \u001b[0;36mfalse_group_norm\u001b[0;34m(x, num_groups, weight, bias, eps)\u001b[0m\n\u001b[1;32m      4\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(B \u001b[38;5;241m*\u001b[39m num_groups, C \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_groups \u001b[38;5;241m*\u001b[39m H \u001b[38;5;241m*\u001b[39m W)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# # x = x.contiguos()\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# mean = x.mean(dim=-1, keepdims=True)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# var = x.var(dim=-1, keepdims=True)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# y = (x - mean) / (var + eps).sqrt()\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mC\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mreshape(B,  num_groups, C \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_groups,  H,  W)\n\u001b[1;32m     13\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mreshape(B,  C,  H,  W)\n",
      "File \u001b[0;32m~/miniforge3/envs/studyenv/lib/python3.10/site-packages/torch/nn/functional.py:2543\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2541\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[1;32m   2542\u001b[0m     )\n\u001b[0;32m-> 2543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected weight to be of same shape as normalized_shape, but got weight of shape [32] and normalized_shape = [16384]"
     ]
    }
   ],
   "source": [
    "torch.allclose(false_group_norm(x, num_groups, weight, bias, eps), true_out, atol=1e-2, rtol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0001, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(false_group_norm(x, num_groups, weight, bias, eps) - true_out).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_group_norm(input_shape, num_groups, dtype, eps=1e-5, device='cuda'):\n",
    "    # create data\n",
    "    B, C, H, W = input_shape\n",
    "    weight = torch.rand(C, dtype=dtype, device='cuda', requires_grad=True)\n",
    "    bias = torch.rand(C, dtype=dtype, device='cuda', requires_grad=True)\n",
    "    x = -2.3 + 0.5 * torch.randn(input_shape, dtype=dtype, device='cuda')\n",
    "    dy = .1 * torch.randn_like(x)\n",
    "\n",
    "    x.requires_grad_(True)\n",
    "    # forward pass\n",
    "    y_tri = group_norm(x, num_groups, weight, bias, eps)\n",
    "    y_ref = torch.nn.functional.group_norm(x, num_groups, weight, bias, eps).to(dtype)\n",
    "    # backward pass (triton)\n",
    "    y_tri.backward(dy, retain_graph=True)\n",
    "    dx_tri, dw_tri, db_tri = [_.grad.clone() for _ in [x, weight, bias]]\n",
    "    x.grad, weight.grad, bias.grad = None, None, None\n",
    "    # backward pass (torch)\n",
    "    y_ref.backward(dy, retain_graph=True)\n",
    "    dx_ref, dw_ref, db_ref = [_.grad.clone() for _ in [x, weight, bias]]\n",
    "    # compare\n",
    "    assert torch.allclose(y_tri, y_ref, atol=1e-2, rtol=0)\n",
    "    assert torch.allclose(dx_tri, dx_ref, atol=1e-2, rtol=0)\n",
    "    assert torch.allclose(db_tri, db_ref, atol=1e-2, rtol=0)\n",
    "    assert torch.allclose(dw_tri, dw_ref, atol=1e-2, rtol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 32, 64, 64)\n",
    "num_groups = 8\n",
    "test_group_norm(input_shape, num_groups, torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1\n",
    "\n",
    "Visualize perfomance benchmark using `triton.testing.perf_report`. Similar to matmul benchmark from seminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to check your implementation for the following parameters\n",
    "batch_size = 2\n",
    "for image_resolution in [32, 128, 512, 1024, 1536, 2048]:\n",
    "    for num_channels in [32, 128, 386, 512]:\n",
    "        for num_groups in [1, 4, 8, 16, 32]:\n",
    "\n",
    "            dummy_input = torch.randn(batch_size, num_channels, image_resolution, image_resolution)\n",
    "\n",
    "            # TODO benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
